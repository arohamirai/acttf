{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Tue Aug 15 19:16:39 2017\\n\\n@author: lile\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 15 19:16:39 2017\n",
    "\n",
    "@author: lile\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识点\n",
    "\"\"\"\n",
    "1. groupby\n",
    "2. map\n",
    "3. lambda\n",
    "4. defaultdict(factory_type)\n",
    "5. str.format() # 格式化字符串\n",
    "6. tf.where()\n",
    "7. tf.map_fn()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建 .TFRecords 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_filenames = glob.glob(\"home/lile/imagenet-dogs/n02*/*.jpg\")\n",
    "\n",
    "from itertools import groupby\n",
    "from collections import defaultdict\n",
    "\n",
    "training_dataset = defaultdict(list)   # \n",
    "testing_dataset  = defaultdict(list)\n",
    "\n",
    "# breed:属; 种类; 类型;\n",
    "# 返回[类型，文件路径]对的列表\n",
    "image_filename_with_breed = list(map(lambda filename:(filename.split(\"/\")[2],filename),\n",
    "                                                 image_filenames))\n",
    "\n",
    "#将key函数作用于原循环器的各个元素,根据key函数结果,\n",
    "#将拥有相同函数结果的元素分到一个新的循环器。每个新的循环器以函数返回结果为标签\n",
    "\n",
    "for dog_breed, breed_images in groupby(image_filename_with_breed ,lambda x:x[0]):\n",
    "    for i, breed_image in enumerate(breed_images):\n",
    "        if i % 5 == 0:\n",
    "            testing_dataset[dog_breed].append(breed_image[1])\n",
    "        else:\n",
    "            training_dataset[dog_breed].append(breed_image[1])\n",
    "            \n",
    "#检查每个品种的测试图像是否至少有全部图像的18%\n",
    "    breed_training_count = len(training_dataset[dog_breed])\n",
    "    breed_testing_count = len(testing_dataset[dog_breed])\n",
    "\n",
    "    assert round(breed_testing_count / (breed_training_count + breed_testing_count), 2) > 0.18, \"Not enough testing images\"\n",
    "\n",
    "def write_records_file(dataset, record_location):\n",
    "    \"\"\"\n",
    "    用  dataset 中的图像填充一个TFRecord文件，并将其类别包含进来\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : dict(list)\n",
    "      Dictionary with each key being a label for the list of image filenames of its value.\n",
    "    record_location : str\n",
    "      Location to store the TFRecord output.\n",
    "    \"\"\"\n",
    "    writer = None\n",
    "\n",
    "    # 枚举dataset， 每个TFRecord文件记录100副图像，以加快写操作\n",
    "    current_index = 0\n",
    "    for breed, images_filenames in dataset.items():\n",
    "        for image_filename in images_filenames:\n",
    "            if current_index % 100 == 0:\n",
    "                if writer:\n",
    "                    writer.close()\n",
    "                \n",
    "                #格式化字符串\n",
    "                record_filename = \"{record_location}-{current_index}.tfrecords\".format(\n",
    "                    record_location=record_location,\n",
    "                    current_index=current_index)\n",
    "\n",
    "                writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "            current_index += 1\n",
    "\n",
    "            image_file = tf.read_file(image_filename)\n",
    "\n",
    "            # In ImageNet dogs, there are a few images which TensorFlow doesn't recognize as JPEGs. This\n",
    "            # try/catch will ignore those images.\n",
    "            # 忽略掉tensorflow不能识别的jpeg图像，使用try/catch语句\n",
    "            try:\n",
    "                image = tf.image.decode_jpeg(image_file)\n",
    "            except:\n",
    "                print(image_filename)\n",
    "                continue\n",
    "\n",
    "            # Converting to grayscale saves processing and memory but isn't required.\n",
    "            # 灰度变换（不是必须的）\n",
    "            grayscale_image = tf.image.rgb_to_grayscale(image)\n",
    "            resized_image = tf.image.resize_images(grayscale_image, 250, 151)\n",
    "\n",
    "            # 在这里使用tf.cast,是因为虽然尺寸更改后的图像的数据类型三浮点型，但RGB值尚未转换到[0,1]区间内??\n",
    "            # tf.cast 并不进行缩放\n",
    "            image_bytes = sess.run(tf.cast(resized_image, tf.uint8)).tobytes()\n",
    "\n",
    "            # Instead of using the label as a string, it'd be more efficient to turn it into either an\n",
    "            # integer index or a one-hot encoded rank one tensor.\n",
    "            # https://en.wikipedia.org/wiki/One-hot\n",
    "            # 推荐将label转换为整型或one-hot编码，这将更高效，此处还是将label按字符串使用\n",
    "            image_label = breed.encode(\"utf-8\")\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_label])),\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "            }))\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5721152184e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 创建TFRecord 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrite_records_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"home/lile/output/testing-images/testing-image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwrite_records_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"home/lile/output/training-images/training-image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2395686f6163>\u001b[0m in \u001b[0;36mwrite_records_file\u001b[0;34m(dataset, record_location)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "# 创建TFRecord 文件\n",
    "write_records_file(testing_dataset, \"home/lile/output/testing-images/testing-image\")\n",
    "write_records_file(training_dataset, \"home/lile/output/training-images/training-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once(\"home/lile/output/training-images/*.tfrecords\"))\n",
    "reader = tf.TFRecordReader()\n",
    "# serialized 指向该文件中的下一个图像\n",
    "_, serialized = reader.read(filename_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized,\n",
    "    features={\n",
    "        'label': tf.FixedLenFeature([], tf.string),\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "    })\n",
    "\n",
    "record_image = tf.decode_raw(features['image'], tf.uint8)\n",
    "\n",
    "# Changing the image into this shape helps train and visualize the output by converting it to\n",
    "# be organized like an image.\n",
    "# 图像已经灰度化了\n",
    "image = tf.reshape(record_image, [250, 151, 1])\n",
    "\n",
    "label = tf.cast(features['label'], tf.string)\n",
    "\n",
    "min_after_dequeue = 10\n",
    "batch_size = 3\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "image_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=batch_size, num_threads = 4, capacity=capacity, min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将图像转换为float32型,并归一化到[0,1]\n",
    "float_image_batch = tf.image.convert_image_dtype(image_batch, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一层\n",
    "    32个5x5大小的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "    float_image_batch,\n",
    "    num_output_channels=32,     # 滤波器数量\n",
    "    kernel_size=(5,5),          # It's only the filter height and width.\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weight_init=tf.random_normal,\n",
    "    stride=(2, 2),\n",
    "    trainable=True)\n",
    "\n",
    "pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')\n",
    "\n",
    "# Note, the first and last dimension of the convolution output hasn't changed but the\n",
    "# middle two dimensions have.\n",
    "conv2d_layer_one.get_shape(), pool_layer_one.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二层\n",
    "    64个5x5大小卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "    pool_layer_one,\n",
    "    num_output_channels=64,        # More output channels means an increase in the number of filters\n",
    "    kernel_size=(5,5),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weight_init=tf.random_normal,\n",
    "    stride=(1, 1),\n",
    "    trainable=True)\n",
    "\n",
    "pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')\n",
    "\n",
    "conv2d_layer_two.get_shape(), pool_layer_two.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一全连接层\n",
    "    512个节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened_layer_two = tf.reshape(\n",
    "    pool_layer_two,\n",
    "    [\n",
    "        batch_size,  # Each image in the image_batch\n",
    "        -1           # Every other dimension of the input\n",
    "    ])\n",
    "\n",
    "flattened_layer_two.get_shape()\n",
    "\n",
    "# The weight_init parameter can also accept a callable, a lambda is used here  returning a truncated normal\n",
    "# with a stddev specified.\n",
    "hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "    flattened_layer_two,\n",
    "    512,\n",
    "    weight_init=lambda i, dtype: tf.truncated_normal([38912, 512], stddev=0.1),\n",
    "    activation_fn=tf.nn.relu\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout层\n",
    "    prob = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout some of the neurons, reducing their importance in the model\n",
    "hidden_layer_three = tf.nn.dropout(hidden_layer_three, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二全连接层\n",
    "    120个节点，即120个类目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The output of this are all the connections between the previous layers and the 120 different dog breeds\n",
    "# available to train on.\n",
    "final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "    hidden_layer_three,\n",
    "    120,  # Number of dog breeds in the ImageNet Dogs dataset\n",
    "    weight_init=lambda i, dtype: tf.truncated_normal([512, 120], stddev=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先将label由字符串形式转换为数字形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find every directory name in the imagenet-dogs directory (n02085620-Chihuahua, ...)\n",
    "# c.split(\"/\")[-1]: -1表示最后一个‘/’\n",
    "labels = list(map(lambda c: c.split(\"/\")[-1], glob.glob(\"home/lile/imagenet-dogs/*\")))\n",
    "\n",
    "# Match every label from label_batch and return the index where they exist in the list of classes\n",
    "train_labels = tf.map_fn(lambda l: tf.where(tf.equal(labels, l))[0,0:1][0], label_batch, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup-only-ignore\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        final_fully_connected, train_labels))\n",
    "\n",
    "batch = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01,\n",
    "    batch * 3,\n",
    "    120,\n",
    "    0.95,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate, 0.9).minimize(\n",
    "    loss, global_step=batch)\n",
    "\n",
    "train_prediction = tf.nn.softmax(final_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
